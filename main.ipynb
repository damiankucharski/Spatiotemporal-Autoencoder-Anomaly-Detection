{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python385jvsc74a57bd04af209406112437305cc6779376bf0e5f0577771d14151e7fd4f38db0fe15105",
   "display_name": "Python 3.8.5 64-bit ('base': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import FileDataset, AnomalyDataset, cache\n",
    "from net import SpatialEncoder\n",
    "from pathlib import Path\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import wandb\n",
    "import tqdm\n",
    "import gc\n",
    "import numpy as np\n",
    "import scipy.io as sio\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from pathlib import Path\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import tqdm\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset\n",
    "from collections import namedtuple\n",
    "import tqdm\n",
    "from torchvision.transforms import Resize, Compose, ToPILImage, ToTensor\n",
    "from PIL import Image\n",
    "import torch.nn.functional as F\n",
    "from conv_lstm import ConvLSTM\n",
    "import neptune\n",
    "import wandb\n",
    "from PIL import Image\n",
    "from matplotlib import cm\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "wandb: Currently logged in as: damiankucharski (use `wandb login --relogin` to force relogin)\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "\n                Tracking run with wandb version 0.10.30<br/>\n                Syncing run <strong style=\"color:#cdcd00\">legendary-energy-13</strong> to <a href=\"https://wandb.ai\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n                Project page: <a href=\"https://wandb.ai/coinitialized/anomaly\" target=\"_blank\">https://wandb.ai/coinitialized/anomaly</a><br/>\n                Run page: <a href=\"https://wandb.ai/coinitialized/anomaly/runs/1lagkkpx\" target=\"_blank\">https://wandb.ai/coinitialized/anomaly/runs/1lagkkpx</a><br/>\n                Run data is saved locally in <code>c:\\Users\\cdami\\Documents\\Python Scripts\\Spatiotemporal-Autoencoder-Anomaly-Detection\\wandb\\run-20210523_134934-1lagkkpx</code><br/><br/>\n            "
     },
     "metadata": {}
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/html": "<h1>Run(1lagkkpx)</h1><iframe src=\"https://wandb.ai/coinitialized/anomaly/runs/1lagkkpx\" style=\"border:none;width:100%;height:400px\"></iframe>",
      "text/plain": [
       "<wandb.sdk.wandb_run.Run at 0x239b7f449a0>"
      ]
     },
     "metadata": {},
     "execution_count": 2
    }
   ],
   "source": [
    "wandb.init(project='anomaly', entity='coinitialized')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_path = Path('Avenue Dataset/training_vol')\n",
    "test_path = Path('Avenue Dataset/testing_vol')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda')\n",
    "model = SpatialEncoder()\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(model.parameters())\n",
    "loss = nn.MSELoss()\n",
    "epochs = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_train = FileDataset(train_path, test_path, train=True) \n",
    "set_test = FileDataset(train_path, test_path, train=False)\n",
    "\n",
    "train_data_loader = torch.utils.data.DataLoader(set_train, batch_size=1, shuffle=True)\n",
    "test_data_loader = torch.utils.data.DataLoader(set_test, batch_size=1, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "losses_train = []\n",
    "losses_test = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "  0%|          | 0/50 [00:00<?, ?it/s]\n",
      "  0%|          | 0/16 [00:00<?, ?it/s]\u001b[Atrain\n",
      "Generating strides for Avenue Dataset\\training_vol\\vol02.mat\n",
      "Generating strides for Avenue Dataset\\training_vol\\vol02.mat\n",
      "Generating strides for Avenue Dataset\\training_vol\\vol02.mat\n",
      "<class 'torch.Tensor'>\n",
      "torch.Size([1, 2753, 1, 10, 227, 227])\n",
      "2202\n",
      "C:\\Users\\cdami\\Anaconda3\\lib\\site-packages\\torch\\nn\\functional.py:1628: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n",
      "C:\\Users\\cdami\\Anaconda3\\lib\\site-packages\\torch\\nn\\functional.py:1639: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
      "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n",
      "\n",
      "  6%|▋         | 1/16 [03:03<45:45, 183.05s/it]\u001b[AGenerating strides for Avenue Dataset\\training_vol\\vol01.mat\n",
      "Generating strides for Avenue Dataset\\training_vol\\vol01.mat\n",
      "Generating strides for Avenue Dataset\\training_vol\\vol01.mat\n",
      "<class 'torch.Tensor'>\n",
      "torch.Size([1, 2483, 1, 10, 227, 227])\n",
      "1986\n",
      "\n",
      " 12%|█▎        | 2/16 [05:39<40:50, 175.07s/it]\u001b[AGenerating strides for Avenue Dataset\\training_vol\\vol15.mat\n",
      "Generating strides for Avenue Dataset\\training_vol\\vol15.mat\n",
      "Generating strides for Avenue Dataset\\training_vol\\vol15.mat\n",
      "<class 'torch.Tensor'>\n",
      "torch.Size([1, 630, 1, 10, 227, 227])\n",
      "504\n",
      "\n",
      " 19%|█▉        | 3/16 [06:15<28:54, 133.40s/it]\u001b[AGenerating strides for Avenue Dataset\\training_vol\\vol03.mat\n",
      "Generating strides for Avenue Dataset\\training_vol\\vol03.mat\n",
      "Generating strides for Avenue Dataset\\training_vol\\vol03.mat\n",
      "<class 'torch.Tensor'>\n",
      "torch.Size([1, 2709, 1, 10, 227, 227])\n",
      "2167\n",
      "\n",
      " 25%|██▌       | 4/16 [09:12<29:17, 146.46s/it]\u001b[AGenerating strides for Avenue Dataset\\training_vol\\vol10.mat\n",
      "Generating strides for Avenue Dataset\\training_vol\\vol10.mat\n",
      "Generating strides for Avenue Dataset\\training_vol\\vol10.mat\n",
      "<class 'torch.Tensor'>\n",
      "torch.Size([1, 2225, 1, 10, 227, 227])\n",
      "1780\n",
      "\n",
      " 31%|███▏      | 5/16 [11:37<26:44, 145.86s/it]\u001b[AGenerating strides for Avenue Dataset\\training_vol\\vol06.mat\n",
      "Generating strides for Avenue Dataset\\training_vol\\vol06.mat\n",
      "Generating strides for Avenue Dataset\\training_vol\\vol06.mat\n",
      "<class 'torch.Tensor'>\n",
      "torch.Size([1, 2753, 1, 10, 227, 227])\n",
      "2202\n",
      "\n",
      " 38%|███▊      | 6/16 [14:33<25:50, 155.06s/it]\u001b[AGenerating strides for Avenue Dataset\\training_vol\\vol16.mat\n",
      "Generating strides for Avenue Dataset\\training_vol\\vol16.mat\n",
      "Generating strides for Avenue Dataset\\training_vol\\vol16.mat\n",
      "<class 'torch.Tensor'>\n",
      "torch.Size([1, 429, 1, 10, 227, 227])\n",
      "343\n",
      "\n",
      " 44%|████▍     | 7/16 [14:59<17:26, 116.24s/it]\u001b[AGenerating strides for Avenue Dataset\\training_vol\\vol05.mat\n",
      "Generating strides for Avenue Dataset\\training_vol\\vol05.mat\n",
      "Generating strides for Avenue Dataset\\training_vol\\vol05.mat\n",
      "<class 'torch.Tensor'>\n",
      "torch.Size([1, 1477, 1, 10, 227, 227])\n",
      "1181\n",
      "\n",
      " 50%|█████     | 8/16 [16:25<14:17, 107.16s/it]\u001b[AGenerating strides for Avenue Dataset\\training_vol\\vol08.mat\n",
      "Generating strides for Avenue Dataset\\training_vol\\vol08.mat\n",
      "Generating strides for Avenue Dataset\\training_vol\\vol08.mat\n",
      "<class 'torch.Tensor'>\n",
      "torch.Size([1, 1847, 1, 10, 227, 227])\n",
      "1477\n",
      "\n",
      " 56%|█████▋    | 9/16 [18:20<12:46, 109.45s/it]\u001b[AGenerating strides for Avenue Dataset\\training_vol\\vol04.mat\n",
      "Generating strides for Avenue Dataset\\training_vol\\vol04.mat\n",
      "Generating strides for Avenue Dataset\\training_vol\\vol04.mat\n",
      "<class 'torch.Tensor'>\n",
      "torch.Size([1, 2753, 1, 10, 227, 227])\n",
      "2202\n",
      "\n",
      " 62%|██████▎   | 10/16 [21:22<13:08, 131.39s/it]\u001b[AGenerating strides for Avenue Dataset\\training_vol\\vol09.mat\n",
      "Generating strides for Avenue Dataset\\training_vol\\vol09.mat\n",
      "Generating strides for Avenue Dataset\\training_vol\\vol09.mat\n",
      "<class 'torch.Tensor'>\n",
      "torch.Size([1, 2533, 1, 10, 227, 227])\n",
      "2026\n",
      "\n",
      " 69%|██████▉   | 11/16 [24:12<11:54, 142.86s/it]\u001b[AGenerating strides for Avenue Dataset\\training_vol\\vol07.mat\n",
      "Generating strides for Avenue Dataset\\training_vol\\vol07.mat\n",
      "Generating strides for Avenue Dataset\\training_vol\\vol07.mat\n",
      "<class 'torch.Tensor'>\n",
      "torch.Size([1, 1997, 1, 10, 227, 227])\n",
      "1597\n",
      "\n",
      " 75%|███████▌  | 12/16 [26:26<09:20, 140.21s/it]\u001b[AGenerating strides for Avenue Dataset\\training_vol\\vol14.mat\n",
      "Generating strides for Avenue Dataset\\training_vol\\vol14.mat\n",
      "Generating strides for Avenue Dataset\\training_vol\\vol14.mat\n",
      "<class 'torch.Tensor'>\n",
      "torch.Size([1, 917, 1, 10, 227, 227])\n",
      "733\n",
      "\n",
      " 81%|████████▏ | 13/16 [27:22<05:45, 115.14s/it]\u001b[AGenerating strides for Avenue Dataset\\training_vol\\vol12.mat\n",
      "Generating strides for Avenue Dataset\\training_vol\\vol12.mat\n",
      "Generating strides for Avenue Dataset\\training_vol\\vol12.mat\n",
      "<class 'torch.Tensor'>\n",
      "torch.Size([1, 248, 1, 10, 227, 227])\n",
      "198\n",
      "\n",
      " 88%|████████▊ | 14/16 [27:37<02:50, 85.11s/it] \u001b[AGenerating strides for Avenue Dataset\\training_vol\\vol11.mat\n",
      "Generating strides for Avenue Dataset\\training_vol\\vol11.mat\n",
      "Generating strides for Avenue Dataset\\training_vol\\vol11.mat\n",
      "<class 'torch.Tensor'>\n",
      "torch.Size([1, 1414, 1, 10, 227, 227])\n",
      "1131\n",
      "\n",
      " 94%|█████████▍| 15/16 [29:04<01:25, 85.53s/it]\u001b[AGenerating strides for Avenue Dataset\\training_vol\\vol13.mat\n",
      "Generating strides for Avenue Dataset\\training_vol\\vol13.mat\n",
      "Generating strides for Avenue Dataset\\training_vol\\vol13.mat\n",
      "<class 'torch.Tensor'>\n",
      "torch.Size([1, 653, 1, 10, 227, 227])\n",
      "522\n",
      "\n",
      "100%|██████████| 16/16 [29:45<00:00, 111.57s/it]\n",
      "  0%|          | 0/50 [29:45<?, ?it/s]\n"
     ]
    },
    {
     "output_type": "error",
     "ename": "NameError",
     "evalue": "name 'np' is not defined",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-8-416a18f054a4>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     26\u001b[0m         \u001b[1;32mdel\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 28\u001b[1;33m     \u001b[0mlosses_train\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_loss_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     29\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     30\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'test'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'np' is not defined"
     ]
    }
   ],
   "source": [
    "for i in tqdm.tqdm(range(epochs)):\n",
    "\n",
    "    print('train')\n",
    "    batch_loss_train = []\n",
    "    model.train()\n",
    "\n",
    "    batch_loss_train = []\n",
    "    for X in tqdm.tqdm(train_data_loader):\n",
    "\n",
    "\n",
    "        print(type(X))\n",
    "        print(X.size())\n",
    "\n",
    "        set_train = AnomalyDataset(X[0], train=True) \n",
    "        print(len(set_train))\n",
    "        train_loader = torch.utils.data.DataLoader(set_train, batch_size=12, shuffle=True)\n",
    "        for X_batch in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "            X_batch = X_batch.to(device)\n",
    "            predictions = model(X_batch)\n",
    "            loss_val = loss(predictions, X_batch)\n",
    "            batch_loss_train.append(loss_val.item())\n",
    "            loss_val.backward()\n",
    "            optimizer.step()\n",
    "            del X_batch\n",
    "            gc.collect()\n",
    "        del X\n",
    "        gc.collect()\n",
    "\n",
    "    losses_train.append(np.mean(batch_loss_train))\n",
    "\n",
    "    print('test')\n",
    "    batch_loss_test = []\n",
    "    for X in tqdm.tqdm(test_data_loader):\n",
    "        \n",
    "        set_test = AnomalyDataset(X[0], train=True) \n",
    "        test_loader = torch.utils.data.DataLoader(set_train, batch_size=12, shuffle=True)\n",
    "\n",
    "        model.eval()\n",
    "        batch_loss_test = []\n",
    "        for X_batch in test_loader:\n",
    "            X_batch = X_batch.to(device)\n",
    "            predictions = model(X_batch)\n",
    "            loss_val = loss(predictions, X_batch)\n",
    "            batch_loss_test.append(loss_val.item())\n",
    "            del X_batch\n",
    "            gc.collect()\n",
    "        del X\n",
    "        gc.collect()\n",
    "    \n",
    "    losses_test.append(np.mean(batch_loss_train))\n",
    "\n",
    "    output_image = predictions[:1,...]\n",
    "    output_image = output_image.squeeze()\n",
    "    one_frame = output_image[0,...]\n",
    "    one_frame_numpy = one_frame.cpu().detach().numpy()\n",
    "    im = Image.fromarray(np.uint8(cm.gist_earth(one_frame_numpy)*255))\n",
    "\n",
    "    wandb.log({\"loss_train\": losses_train[-1],\"loss_test\": losses_test[-1], \"epoch\": i,\n",
    "            \"inputs\": wandb.Image(im),\n",
    "            })\n",
    "\n",
    "\n",
    "    PATH = f\"checkpoints/{i}_model.pt\"\n",
    "\n",
    "    torch.save({\n",
    "            'epoch': i,\n",
    "            'model_state_dict': model.state_dict(),\n",
    "            'optimizer_state_dict': optimizer.state_dict(),\n",
    "            'loss_train': losses_train[-1],\n",
    "            'loss_test' : losses_test[-1]\n",
    "            }, PATH)\n",
    "\n",
    "    if losses_test[i-5] - losses_test[i-1] < 0.00025:\n",
    "      break\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}